{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5844f015",
   "metadata": {},
   "source": [
    "# Data Preparation Complete - Walmart Sales Forecast\n",
    "\n",
    "Notebook n√†y th·ª±c hi·ªán to√†n b·ªô c√°c b∆∞·ªõc chu·∫©n b·ªã d·ªØ li·ªáu theo file \"[C√°c b∆∞·ªõc l√†m tham kh·∫£o ti·∫øp theo]\".\n",
    "\n",
    "## C·∫•u tr√∫c:\n",
    "\n",
    "**GIAI ƒêO·∫†N 1: CHU·∫®N B·ªä D·ªÆ LI·ªÜU**\n",
    "- 1.1. T·∫°o df_main_weekly\n",
    "- 1.2. T·∫°o df_events_daily  \n",
    "- 1.3. T·∫°o df_feature_calendar_weekly\n",
    "\n",
    "**GIAI ƒêO·∫†N 2: FEATURE ENGINEERING**\n",
    "- 2.1. Merge & Ki·ªÉm tra\n",
    "- 2.2. T·∫°o Features \"Payday Pulse\"\n",
    "- 2.3. T·∫°o Features \"Holiday\"\n",
    "- 2.4. T·∫°o Features \"Lag/Rolling\"\n",
    "- 2.5. T·∫°o Features \"Interaction\"\n",
    "\n",
    "**GIAI ƒêO·∫†N 3: L∆ØU C√ÅC FILE OUTPUT**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fb10e",
   "metadata": {},
   "source": [
    "## 0. Setup v√† Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeab1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# C·∫•u h√¨nh pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1fc43",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "ƒê·ªãnh nghƒ©a c√°c helper functions (t·ª´ file `data_prep_utils.py`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b54b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def get_us_holidays(year):\n",
    "    \"\"\"T√≠nh c√°c ng√†y l·ªÖ M·ªπ cho m·ªôt nƒÉm\"\"\"\n",
    "    holidays = {}\n",
    "    \n",
    "    holidays[f'{year}-01-01'] = ('New Years Day', 1)\n",
    "    \n",
    "    # Super Bowl\n",
    "    super_bowl_dates = {2010: '2010-02-07', 2011: '2011-02-06', 2012: '2012-02-05'}\n",
    "    if year in super_bowl_dates:\n",
    "        holidays[super_bowl_dates[year]] = ('Super Bowl', 3)\n",
    "    \n",
    "    # Presidents Day\n",
    "    presidents_day_dates = {2010: '2010-02-15', 2011: '2011-02-21', 2012: '2012-02-20'}\n",
    "    if year in presidents_day_dates:\n",
    "        holidays[presidents_day_dates[year]] = ('Presidents Day', 1)\n",
    "    \n",
    "    # Memorial Day\n",
    "    memorial_day_dates = {2010: '2010-05-31', 2011: '2011-05-30', 2012: '2012-05-28'}\n",
    "    if year in memorial_day_dates:\n",
    "        holidays[memorial_day_dates[year]] = ('Memorial Day', 1)\n",
    "    \n",
    "    holidays[f'{year}-07-04'] = ('Independence Day', 1)\n",
    "    \n",
    "    # Labor Day\n",
    "    labor_day_dates = {2010: '2010-09-06', 2011: '2011-09-05', 2012: '2012-09-03'}\n",
    "    if year in labor_day_dates:\n",
    "        holidays[labor_day_dates[year]] = ('Labor Day', 3)\n",
    "    \n",
    "    # Thanksgiving\n",
    "    thanksgiving_dates = {2010: '2010-11-25', 2011: '2011-11-24', 2012: '2012-11-22'}\n",
    "    if year in thanksgiving_dates:\n",
    "        holidays[thanksgiving_dates[year]] = ('Thanksgiving', 5)\n",
    "    \n",
    "    holidays[f'{year}-12-25'] = ('Christmas', 5)\n",
    "    holidays[f'{year}-12-24'] = ('Christmas Eve', 3)\n",
    "    \n",
    "    return holidays\n",
    "\n",
    "\n",
    "def get_week_end_date(date):\n",
    "    \"\"\"T√≠nh WeekEndDate (Th·ª© S√°u cu·ªëi tu·∫ßn) cho m·ªôt ng√†y\"\"\"\n",
    "    weekday = date.weekday()  # 0=Monday, 4=Friday, 6=Sunday\n",
    "    if weekday == 4:  # Friday\n",
    "        return date\n",
    "    elif weekday == 5:  # Saturday\n",
    "        return date + timedelta(days=6)\n",
    "    elif weekday == 6:  # Sunday\n",
    "        return date + timedelta(days=5)\n",
    "    else:  # Monday-Thursday\n",
    "        return date + timedelta(days=4-weekday)\n",
    "\n",
    "\n",
    "def is_tax_refund_season(date):\n",
    "    \"\"\"Ki·ªÉm tra xem ng√†y c√≥ thu·ªôc m√πa ho√†n thu·∫ø kh√¥ng (15/02 - 15/04)\"\"\"\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    if month == 2 and day >= 15:\n",
    "        return 1\n",
    "    elif month == 3:\n",
    "        return 1\n",
    "    elif month == 4 and day <= 15:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def calculate_weeks_since_payday(group):\n",
    "    \"\"\"T√≠nh s·ªë tu·∫ßn k·ªÉ t·ª´ payday g·∫ßn nh·∫•t cho m·ªói group (Store, Dept)\"\"\"\n",
    "    weeks_since = []\n",
    "    last_payday_week = None\n",
    "    \n",
    "    for idx, row in group.iterrows():\n",
    "        if row['is_semimonthly_payweek'] == 1:\n",
    "            last_payday_week = row['WeekEndDate']\n",
    "            weeks_since.append(0)\n",
    "        elif last_payday_week is not None:\n",
    "            weeks_diff = (row['WeekEndDate'] - last_payday_week).days // 7\n",
    "            weeks_since.append(weeks_diff)\n",
    "        else:\n",
    "            weeks_since.append(np.nan)\n",
    "    \n",
    "    return pd.Series(weeks_since, index=group.index)\n",
    "\n",
    "\n",
    "def piecewise_decay(weeks):\n",
    "    \"\"\"T√≠nh gi√° tr·ªã decay theo piecewise function\"\"\"\n",
    "    if weeks == 0:\n",
    "        return 1.0\n",
    "    elif weeks == 1:\n",
    "        return 0.7\n",
    "    elif weeks >= 2:\n",
    "        return 0.4\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def get_christmas_date(year):\n",
    "    \"\"\"Tr·∫£ v·ªÅ ng√†y Gi√°ng sinh\"\"\"\n",
    "    return pd.Timestamp(f'{year}-12-25')\n",
    "\n",
    "\n",
    "def get_thanksgiving_date(year):\n",
    "    \"\"\"T√≠nh ng√†y Thanksgiving (Th·ª© 5 th·ª© 4 c·ªßa th√°ng 11)\"\"\"\n",
    "    nov_1 = pd.Timestamp(f'{year}-11-01')\n",
    "    first_thursday = nov_1 + timedelta(days=(3 - nov_1.weekday()) % 7)\n",
    "    if first_thursday.day > 7:\n",
    "        first_thursday = first_thursday - timedelta(days=7)\n",
    "    thanksgiving = first_thursday + timedelta(days=21)\n",
    "    return thanksgiving\n",
    "\n",
    "\n",
    "def calculate_weeks_until_holiday(date, holiday_func):\n",
    "    \"\"\"T√≠nh s·ªë tu·∫ßn cho ƒë·∫øn l·ªÖ ti·∫øp theo\"\"\"\n",
    "    year = date.year\n",
    "    holiday_date = holiday_func(year)\n",
    "    \n",
    "    # N·∫øu l·ªÖ ƒë√£ qua trong nƒÉm n√†y, t√≠nh l·ªÖ nƒÉm sau\n",
    "    if date > holiday_date:\n",
    "        holiday_date = holiday_func(year + 1)\n",
    "    \n",
    "    weeks_diff = (holiday_date - date).days // 7\n",
    "    return weeks_diff\n",
    "\n",
    "print(\"‚úÖ Helper functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afff556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Data path: ../data/\n",
      "üìÅ Processed path: ../data/processed/\n"
     ]
    }
   ],
   "source": [
    "# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n\n",
    "DATA_PATH = '../data/'\n",
    "PROCESSED_PATH = '../data/processed/'\n",
    "\n",
    "print(f\"üìÅ Data path: {DATA_PATH}\")\n",
    "print(f\"üìÅ Processed path: {PROCESSED_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f29b80",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# GIAI ƒêO·∫†N 1: CHU·∫®N B·ªä D·ªÆ LI·ªÜU\n",
    "\n",
    "## 1.1. T·∫°o df_main_weekly\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- Merge 3 files: train.csv, stores.csv, features.csv\n",
    "- X·ª≠ l√Ω MarkDowns (fillna, t·∫°o features)\n",
    "- X·ª≠ l√Ω Weekly_Sales √¢m (returns)\n",
    "- Validation d·ªØ li·ªáu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e968282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading datasets...\n",
      "üìà Train data shape: (421570, 5)\n",
      "üè™ Stores data shape: (45, 3)\n",
      "üå°Ô∏è Features data shape: (8190, 12)\n"
     ]
    }
   ],
   "source": [
    "# Load c√°c datasets\n",
    "print(\"üîÑ Loading datasets...\")\n",
    "train_df = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "stores_df = pd.read_csv(DATA_PATH + 'stores.csv')\n",
    "features_df = pd.read_csv(DATA_PATH + 'features.csv')\n",
    "\n",
    "print(f\"üìà Train data shape: {train_df.shape}\")\n",
    "print(f\"üè™ Stores data shape: {stores_df.shape}\")\n",
    "print(f\"üå°Ô∏è Features data shape: {features_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3345d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Merging datasets...\n",
      "‚úÖ Merged data shape: (421570, 16)\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>46039.49</td>\n",
       "      <td>True</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>41595.55</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>19403.54</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday Type    Size  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  Unemployment\n",
       "0      1     1  2010-02-05      24924.50      False    A  151315        42.31       2.572        NaN        NaN        NaN        NaN        NaN  211.096358         8.106\n",
       "1      1     1  2010-02-12      46039.49       True    A  151315        38.51       2.548        NaN        NaN        NaN        NaN        NaN  211.242170         8.106\n",
       "2      1     1  2010-02-19      41595.55      False    A  151315        39.93       2.514        NaN        NaN        NaN        NaN        NaN  211.289143         8.106\n",
       "3      1     1  2010-02-26      19403.54      False    A  151315        46.63       2.561        NaN        NaN        NaN        NaN        NaN  211.319643         8.106\n",
       "4      1     1  2010-03-05      21827.90      False    A  151315        46.50       2.625        NaN        NaN        NaN        NaN        NaN  211.350143         8.106"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge 3 files\n",
    "print(\"üîÑ Merging datasets...\")\n",
    "df_main = pd.merge(train_df, stores_df, on='Store', how='left')\n",
    "df_main = pd.merge(df_main, features_df, on=['Store', 'Date'], how='left', suffixes=('', '_features'))\n",
    "\n",
    "# X·ª≠ l√Ω duplicate IsHoliday columns\n",
    "if 'IsHoliday_features' in df_main.columns:\n",
    "    df_main = df_main.drop(columns=['IsHoliday_features'])\n",
    "\n",
    "print(f\"‚úÖ Merged data shape: {df_main.shape}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df_main.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aca1766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Time range: 2010-02-05 00:00:00 to 2012-10-26 00:00:00\n",
      "\n",
      "Weekday distribution:\n",
      "WeekDay\n",
      "Friday    421570\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Chuy·ªÉn ƒë·ªïi Date sang datetime v√† ƒë·ªïi t√™n th√†nh WeekEndDate\n",
    "df_main['Date'] = pd.to_datetime(df_main['Date'])\n",
    "df_main = df_main.rename(columns={'Date': 'WeekEndDate'})\n",
    "\n",
    "print(f\"üìÖ Time range: {df_main['WeekEndDate'].min()} to {df_main['WeekEndDate'].max()}\")\n",
    "\n",
    "# Ki·ªÉm tra WeekEndDate c√≥ ph·∫£i l√† Th·ª© S√°u kh√¥ng\n",
    "df_main['WeekDay'] = df_main['WeekEndDate'].dt.day_name()\n",
    "print(f\"\\nWeekday distribution:\")\n",
    "print(df_main['WeekDay'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a320acfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä MarkDowns missing (all zeros): 270138 records\n",
      "\n",
      "MarkDowns sum statistics:\n",
      "count    421570.000000\n",
      "mean       6684.041435\n",
      "std       14750.941552\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%        8075.260000\n",
      "max      160510.610000\n",
      "Name: md_sum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# X·ª≠ l√Ω MarkDowns\n",
    "markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
    "\n",
    "# Fill NA v·ªõi 0\n",
    "for col in markdown_cols:\n",
    "    df_main[col] = df_main[col].fillna(0)\n",
    "\n",
    "# T·∫°o md_missing_any: = 1 n·∫øu c·∫£ 5 c·ªôt ƒë·ªÅu l√† 0\n",
    "df_main['md_missing_any'] = ((df_main[markdown_cols] == 0).all(axis=1)).astype(int)\n",
    "\n",
    "# T·∫°o md_sum: T·ªïng gi√° tr·ªã c·ªßa 5 c·ªôt MarkDown\n",
    "df_main['md_sum'] = df_main[markdown_cols].sum(axis=1)\n",
    "\n",
    "print(f\"üìä MarkDowns missing (all zeros): {df_main['md_missing_any'].sum()} records\")\n",
    "print(f\"\\nMarkDowns sum statistics:\")\n",
    "print(df_main['md_sum'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42be6fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Negative sales processed: 1285 records\n",
      "üìä Total returns value: $88,161.56\n",
      "‚úÖ All Weekly_Sales are now >= 0\n"
     ]
    }
   ],
   "source": [
    "# X·ª≠ l√Ω Weekly_Sales √¢m\n",
    "# T·∫°o returns_flag v√† returns_abs tr∆∞·ªõc khi clip\n",
    "df_main['returns_flag'] = (df_main['Weekly_Sales'] < 0).astype(int)\n",
    "df_main['returns_abs'] = df_main['Weekly_Sales'].apply(lambda x: abs(x) if x < 0 else 0)\n",
    "\n",
    "print(f\"üìä Negative sales processed: {df_main['returns_flag'].sum()} records\")\n",
    "print(f\"üìä Total returns value: ${df_main['returns_abs'].sum():,.2f}\")\n",
    "\n",
    "# Clip Weekly_Sales v·ªÅ >= 0\n",
    "df_main['Weekly_Sales'] = df_main['Weekly_Sales'].clip(lower=0)\n",
    "\n",
    "print(f\"‚úÖ All Weekly_Sales are now >= 0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "338a9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Validating data quality...\n",
      "‚úÖ All validations passed!\n",
      "\n",
      "üìä df_main_weekly created! Shape: (421570, 21)\n",
      "üìä Columns: 21\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(\"üîç Validating data quality...\")\n",
    "\n",
    "# Ki·ªÉm tra WeekEndDate kh√¥ng b·ªã NA\n",
    "assert df_main['WeekEndDate'].notna().all(), \"WeekEndDate has NA!\"\n",
    "\n",
    "# Ki·ªÉm tra Store v√† Dept kh√¥ng b·ªã NA\n",
    "assert df_main['Store'].notna().all(), \"Store has NA!\"\n",
    "assert df_main['Dept'].notna().all(), \"Dept has NA!\"\n",
    "\n",
    "# Ki·ªÉm tra Weekly_Sales (sau clip) kh√¥ng √¢m\n",
    "assert (df_main['Weekly_Sales'] >= 0).all(), \"Weekly_Sales still negative!\"\n",
    "\n",
    "print(\"‚úÖ All validations passed!\")\n",
    "\n",
    "# L∆∞u df_main_weekly\n",
    "df_main_weekly = df_main.copy()\n",
    "print(f\"\\nüìä df_main_weekly created! Shape: {df_main_weekly.shape}\")\n",
    "print(f\"üìä Columns: {len(df_main_weekly.columns)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928c612",
   "metadata": {},
   "source": [
    "## 1.2. T·∫°o df_events_daily\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- T·∫°o l·ªãch daily t·ª´ min_date ƒë·∫øn max_date\n",
    "- Th√™m features Payday (SNAP, semimonthly, tax refund)\n",
    "- T·∫°o l·ªãch Holiday events cho M·ªπ (2010-2012)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ada3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Date range: 2010-02-05 to 2012-10-26\n",
      "üìÖ Total days: 995\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o l·ªãch daily t·ª´ min_date ƒë·∫øn max_date\n",
    "min_date = df_main_weekly['WeekEndDate'].min()\n",
    "max_date = df_main_weekly['WeekEndDate'].max()\n",
    "\n",
    "date_range = pd.date_range(start=min_date, end=max_date, freq='D')\n",
    "df_events_daily = pd.DataFrame({'Date': date_range})\n",
    "\n",
    "print(f\"üìÖ Date range: {min_date.date()} to {max_date.date()}\")\n",
    "print(f\"üìÖ Total days: {len(df_events_daily)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb0c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Payday features added!\n",
      "   SNAP window 1 days: 326\n",
      "   SNAP window 2 days: 330\n",
      "   Semimonthly payday days: 65\n",
      "   Tax refund season days: 181\n"
     ]
    }
   ],
   "source": [
    "# Th√™m features Payday\n",
    "# is_snap_window_1: ng√†y 1-10\n",
    "df_events_daily['is_snap_window_1'] = (df_events_daily['Date'].dt.day <= 10).astype(int)\n",
    "\n",
    "# is_snap_window_2: ng√†y 11-20\n",
    "df_events_daily['is_snap_window_2'] = ((df_events_daily['Date'].dt.day >= 11) & \n",
    "                                       (df_events_daily['Date'].dt.day <= 20)).astype(int)\n",
    "\n",
    "# is_semimonthly_payday: ng√†y 15 ho·∫∑c cu·ªëi th√°ng\n",
    "df_events_daily['is_semimonthly_payday'] = ((df_events_daily['Date'].dt.day == 15) | \n",
    "                                           (df_events_daily['Date'].dt.is_month_end)).astype(int)\n",
    "\n",
    "# is_tax_refund_season: 15/02 - 15/04 h√†ng nƒÉm\n",
    "df_events_daily['is_tax_refund_season'] = df_events_daily['Date'].apply(is_tax_refund_season)\n",
    "\n",
    "print(\"‚úÖ Payday features added!\")\n",
    "print(f\"   SNAP window 1 days: {df_events_daily['is_snap_window_1'].sum()}\")\n",
    "print(f\"   SNAP window 2 days: {df_events_daily['is_snap_window_2'].sum()}\")\n",
    "print(f\"   Semimonthly payday days: {df_events_daily['is_semimonthly_payday'].sum()}\")\n",
    "print(f\"   Tax refund season days: {df_events_daily['is_tax_refund_season'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e547db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Holiday events added!\n",
      "   Total holidays: 23\n",
      "\n",
      "Holiday distribution:\n",
      "HolidayName\n",
      "Super Bowl          3\n",
      "Presidents Day      3\n",
      "Memorial Day        3\n",
      "Independence Day    3\n",
      "Labor Day           3\n",
      "Thanksgiving        2\n",
      "Christmas Eve       2\n",
      "Christmas           2\n",
      "New Years Day       2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o l·ªãch Holiday events cho M·ªπ (2010-2012)\n",
    "all_holidays = {}\n",
    "for year in [2010, 2011, 2012]:\n",
    "    all_holidays.update(get_us_holidays(year))\n",
    "\n",
    "# Map v√†o df_events_daily\n",
    "df_events_daily['HolidayName'] = df_events_daily['Date'].dt.strftime('%Y-%m-%d').map(\n",
    "    lambda x: all_holidays.get(x, ('', 0))[0] if x in all_holidays else ''\n",
    ")\n",
    "df_events_daily['holiday_impact'] = df_events_daily['Date'].dt.strftime('%Y-%m-%d').map(\n",
    "    lambda x: all_holidays.get(x, ('', 0))[1] if x in all_holidays else 0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Holiday events added!\")\n",
    "print(f\"   Total holidays: {(df_events_daily['HolidayName'] != '').sum()}\")\n",
    "print(f\"\\nHoliday distribution:\")\n",
    "print(df_events_daily[df_events_daily['HolidayName'] != '']['HolidayName'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "967a2b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä df_events_daily shape: (995, 7)\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>is_snap_window_1</th>\n",
       "      <th>is_snap_window_2</th>\n",
       "      <th>is_semimonthly_payday</th>\n",
       "      <th>is_tax_refund_season</th>\n",
       "      <th>HolidayName</th>\n",
       "      <th>holiday_impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Super Bowl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-02-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-02-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-02-13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-02-14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-02-15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Presidents Day</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2010-02-16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2010-02-17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2010-02-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  is_snap_window_1  is_snap_window_2  is_semimonthly_payday  is_tax_refund_season     HolidayName  holiday_impact\n",
       "0  2010-02-05                 1                 0                      0                     0                               0\n",
       "1  2010-02-06                 1                 0                      0                     0                               0\n",
       "2  2010-02-07                 1                 0                      0                     0      Super Bowl               3\n",
       "3  2010-02-08                 1                 0                      0                     0                               0\n",
       "4  2010-02-09                 1                 0                      0                     0                               0\n",
       "5  2010-02-10                 1                 0                      0                     0                               0\n",
       "6  2010-02-11                 0                 1                      0                     0                               0\n",
       "7  2010-02-12                 0                 1                      0                     0                               0\n",
       "8  2010-02-13                 0                 1                      0                     0                               0\n",
       "9  2010-02-14                 0                 1                      0                     0                               0\n",
       "10 2010-02-15                 0                 1                      1                     1  Presidents Day               1\n",
       "11 2010-02-16                 0                 1                      0                     1                               0\n",
       "12 2010-02-17                 0                 1                      0                     1                               0\n",
       "13 2010-02-18                 0                 1                      0                     1                               0\n",
       "14 2010-02-19                 0                 1                      0                     1                               0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xem sample df_events_daily\n",
    "print(\"üìä df_events_daily shape:\", df_events_daily.shape)\n",
    "print(\"\\nSample data:\")\n",
    "df_events_daily.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f267b",
   "metadata": {},
   "source": [
    "## 1.3. T·∫°o df_feature_calendar_weekly\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- Th√™m WeekEndDate v√†o df_events_daily\n",
    "- Groupby WeekEndDate v√† aggregate c√°c features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d82befce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WeekEndDate added to df_events_daily!\n",
      "\n",
      "Sample WeekEndDate mapping:\n",
      "        Date WeekEndDate\n",
      "0 2010-02-05  2010-02-05\n",
      "1 2010-02-06  2010-02-12\n",
      "2 2010-02-07  2010-02-12\n",
      "3 2010-02-08  2010-02-12\n",
      "4 2010-02-09  2010-02-12\n",
      "5 2010-02-10  2010-02-12\n",
      "6 2010-02-11  2010-02-12\n",
      "7 2010-02-12  2010-02-12\n",
      "8 2010-02-13  2010-02-19\n",
      "9 2010-02-14  2010-02-19\n"
     ]
    }
   ],
   "source": [
    "# Th√™m WeekEndDate v√†o df_events_daily\n",
    "df_events_daily['WeekEndDate'] = df_events_daily['Date'].apply(get_week_end_date)\n",
    "\n",
    "print(\"‚úÖ WeekEndDate added to df_events_daily!\")\n",
    "print(f\"\\nSample WeekEndDate mapping:\")\n",
    "print(df_events_daily[['Date', 'WeekEndDate']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e96b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ df_feature_calendar_weekly created! Shape: (143, 7)\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekEndDate</th>\n",
       "      <th>is_snap_window_1_week</th>\n",
       "      <th>is_snap_window_2_week</th>\n",
       "      <th>is_semimonthly_payweek</th>\n",
       "      <th>is_tax_refund_season_week</th>\n",
       "      <th>holiday_impact_week</th>\n",
       "      <th>holiday_name_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Super Bowl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Presidents Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2010-03-19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2010-03-26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2010-04-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2010-04-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WeekEndDate  is_snap_window_1_week  is_snap_window_2_week  is_semimonthly_payweek  is_tax_refund_season_week  holiday_impact_week holiday_name_week\n",
       "0  2010-02-05                      1                      0                       0                          0                    0                  \n",
       "1  2010-02-12                      1                      1                       0                          0                    3        Super Bowl\n",
       "2  2010-02-19                      0                      1                       1                          1                    1    Presidents Day\n",
       "3  2010-02-26                      0                      1                       0                          1                    0                  \n",
       "4  2010-03-05                      1                      0                       1                          1                    0                  \n",
       "5  2010-03-12                      1                      1                       0                          1                    0                  \n",
       "6  2010-03-19                      0                      1                       1                          1                    0                  \n",
       "7  2010-03-26                      0                      1                       0                          1                    0                  \n",
       "8  2010-04-02                      1                      0                       1                          1                    0                  \n",
       "9  2010-04-09                      1                      0                       0                          1                    0                  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Groupby WeekEndDate v√† aggregate\n",
    "df_feature_calendar_weekly = df_events_daily.groupby('WeekEndDate').agg({\n",
    "    'is_snap_window_1': lambda x: 1 if x.sum() > 0 else 0,\n",
    "    'is_snap_window_2': lambda x: 1 if x.sum() > 0 else 0,\n",
    "    'is_semimonthly_payday': lambda x: 1 if x.sum() > 0 else 0,\n",
    "    'is_tax_refund_season': lambda x: 1 if x.sum() > 0 else 0,\n",
    "    'holiday_impact': 'max',\n",
    "    'HolidayName': lambda x: x[x != ''].iloc[0] if (x != '').any() else ''\n",
    "}).reset_index()\n",
    "\n",
    "# ƒê·ªïi t√™n c·ªôt\n",
    "df_feature_calendar_weekly = df_feature_calendar_weekly.rename(columns={\n",
    "    'is_snap_window_1': 'is_snap_window_1_week',\n",
    "    'is_snap_window_2': 'is_snap_window_2_week',\n",
    "    'is_semimonthly_payday': 'is_semimonthly_payweek',\n",
    "    'is_tax_refund_season': 'is_tax_refund_season_week',\n",
    "    'holiday_impact': 'holiday_impact_week',\n",
    "    'HolidayName': 'holiday_name_week'\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ df_feature_calendar_weekly created! Shape: {df_feature_calendar_weekly.shape}\")\n",
    "print(f\"\\nSample data:\")\n",
    "df_feature_calendar_weekly.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae749465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Weekly features statistics:\n",
      "\n",
      "   SNAP window 1 weeks: 75\n",
      "   SNAP window 2 weeks: 76\n",
      "   Semimonthly payweeks: 65\n",
      "   Tax refund season weeks: 28\n",
      "   Weeks with holidays: 22\n"
     ]
    }
   ],
   "source": [
    "# Xem statistics c·ªßa weekly features\n",
    "print(\"üìä Weekly features statistics:\")\n",
    "print(f\"\\n   SNAP window 1 weeks: {df_feature_calendar_weekly['is_snap_window_1_week'].sum()}\")\n",
    "print(f\"   SNAP window 2 weeks: {df_feature_calendar_weekly['is_snap_window_2_week'].sum()}\")\n",
    "print(f\"   Semimonthly payweeks: {df_feature_calendar_weekly['is_semimonthly_payweek'].sum()}\")\n",
    "print(f\"   Tax refund season weeks: {df_feature_calendar_weekly['is_tax_refund_season_week'].sum()}\")\n",
    "print(f\"   Weeks with holidays: {(df_feature_calendar_weekly['holiday_name_week'] != '').sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2589104",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# GIAI ƒêO·∫†N 2: FEATURE ENGINEERING\n",
    "\n",
    "## 2.1. Merge & Ki·ªÉm tra\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- Merge df_main_weekly v·ªõi df_feature_calendar_weekly\n",
    "- Sanity check: ki·ªÉm tra uniqueness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6f24ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Merge completed! Shape: (421570, 27)\n"
     ]
    }
   ],
   "source": [
    "# Merge df_main_weekly v·ªõi df_feature_calendar_weekly\n",
    "df_final = pd.merge(df_main_weekly, df_feature_calendar_weekly, on='WeekEndDate', how='left')\n",
    "\n",
    "# Fillna cho c√°c c·ªôt m·ªõi\n",
    "fill_cols = ['is_snap_window_1_week', 'is_snap_window_2_week', 'is_semimonthly_payweek', \n",
    "             'is_tax_refund_season_week', 'holiday_impact_week']\n",
    "for col in fill_cols:\n",
    "    df_final[col] = df_final[col].fillna(0)\n",
    "\n",
    "df_final['holiday_name_week'] = df_final['holiday_name_week'].fillna('')\n",
    "\n",
    "print(f\"‚úÖ Merge completed! Shape: {df_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b51a5e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Sanity check...\n",
      "‚úÖ No duplicates found! Each (Store, Dept, WeekEndDate) is unique.\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Ki·ªÉm tra uniqueness c·ªßa (Store, Dept, WeekEndDate)\n",
    "print(\"üîç Sanity check...\")\n",
    "duplicates = df_final.groupby(['Store', 'Dept', 'WeekEndDate']).size()\n",
    "if (duplicates > 1).any():\n",
    "    print(f\"‚ö†Ô∏è Warning: Found {((duplicates > 1).sum())} duplicate (Store, Dept, WeekEndDate) combinations!\")\n",
    "    print(duplicates[duplicates > 1].head())\n",
    "else:\n",
    "    print(\"‚úÖ No duplicates found! Each (Store, Dept, WeekEndDate) is unique.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219d456",
   "metadata": {},
   "source": [
    "## 2.2. T·∫°o Features \"Payday Pulse\"\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- T·∫°o weeks_since_payday_15_eom\n",
    "- T·∫°o payday_decay_exp v√† payday_decay_piecewise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c0f55a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ weeks_since_payday_15_eom created!\n",
      "\n",
      "Statistics:\n",
      "count    421570.000000\n",
      "mean         15.445034\n",
      "std         120.555547\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max         999.000000\n",
      "Name: weeks_since_payday_15_eom, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# S·∫Øp x·∫øp theo Store, Dept, WeekEndDate ƒë·ªÉ t√≠nh lag\n",
    "df_final = df_final.sort_values(['Store', 'Dept', 'WeekEndDate']).reset_index(drop=True)\n",
    "\n",
    "# weeks_since_payday_15_eom: ƒê·∫øm s·ªë tu·∫ßn k·ªÉ t·ª´ is_semimonthly_payweek g·∫ßn nh·∫•t\n",
    "df_final['weeks_since_payday_15_eom'] = df_final.groupby(['Store', 'Dept']).apply(\n",
    "    calculate_weeks_since_payday, include_groups=False\n",
    ").reset_index(level=[0, 1], drop=True)\n",
    "\n",
    "# Fillna v·ªõi gi√° tr·ªã l·ªõn (n·∫øu ch∆∞a c√≥ payday n√†o)\n",
    "df_final['weeks_since_payday_15_eom'] = df_final['weeks_since_payday_15_eom'].fillna(999)\n",
    "\n",
    "print(\"‚úÖ weeks_since_payday_15_eom created!\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(df_final['weeks_since_payday_15_eom'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5907b1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Payday decay features created!\n",
      "\n",
      "Payday decay statistics:\n",
      "       payday_decay_exp  payday_decay_piecewise\n",
      "count      4.215700e+05           421570.000000\n",
      "mean       8.514152e-01                0.807216\n",
      "std        1.734981e-01                0.195337\n",
      "min       3.427308e-109                0.400000\n",
      "25%        7.788008e-01                0.700000\n",
      "50%        7.788008e-01                0.700000\n",
      "75%        1.000000e+00                1.000000\n",
      "max        1.000000e+00                1.000000\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o features decay\n",
    "# C√°ch 1: Exponential decay\n",
    "df_final['payday_decay_exp'] = np.exp(-0.25 * df_final['weeks_since_payday_15_eom'])\n",
    "\n",
    "# C√°ch 2: Piecewise decay\n",
    "df_final['payday_decay_piecewise'] = df_final['weeks_since_payday_15_eom'].apply(piecewise_decay)\n",
    "\n",
    "print(\"‚úÖ Payday decay features created!\")\n",
    "print(f\"\\nPayday decay statistics:\")\n",
    "print(df_final[['payday_decay_exp', 'payday_decay_piecewise']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa88e87",
   "metadata": {},
   "source": [
    "## 2.3. T·∫°o Features \"Holiday\"\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- T·∫°o weeks_until_christmas v√† weeks_until_thanksgiving\n",
    "- T·∫°o is_pre_christmas_window_week v√† is_pre_thanksgiving_window_week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b3f709a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Holiday countdown features created!\n",
      "\n",
      "Statistics:\n",
      "   weeks_until_christmas - min: 0, max: 51\n",
      "   weeks_until_thanksgiving - min: 0, max: 51\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o features Holiday countdown\n",
    "df_final['weeks_until_christmas'] = df_final['WeekEndDate'].apply(\n",
    "    lambda x: calculate_weeks_until_holiday(x, get_christmas_date)\n",
    ")\n",
    "df_final['weeks_until_thanksgiving'] = df_final['WeekEndDate'].apply(\n",
    "    lambda x: calculate_weeks_until_holiday(x, get_thanksgiving_date)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Holiday countdown features created!\")\n",
    "print(f\"\\nStatistics:\")\n",
    "print(f\"   weeks_until_christmas - min: {df_final['weeks_until_christmas'].min()}, max: {df_final['weeks_until_christmas'].max()}\")\n",
    "print(f\"   weeks_until_thanksgiving - min: {df_final['weeks_until_thanksgiving'].min()}, max: {df_final['weeks_until_thanksgiving'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f56e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Holiday window features created!\n",
      "   Pre-Christmas weeks: 23856\n",
      "   Pre-Thanksgiving weeks: 17654\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o features Holiday window\n",
    "df_final['is_pre_christmas_window_week'] = (df_final['weeks_until_christmas'] <= 3).astype(int)\n",
    "df_final['is_pre_thanksgiving_window_week'] = (df_final['weeks_until_thanksgiving'] <= 2).astype(int)\n",
    "\n",
    "print(\"‚úÖ Holiday window features created!\")\n",
    "print(f\"   Pre-Christmas weeks: {df_final['is_pre_christmas_window_week'].sum()}\")\n",
    "print(f\"   Pre-Thanksgiving weeks: {df_final['is_pre_thanksgiving_window_week'].sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c42e0",
   "metadata": {},
   "source": [
    "## 2.4. T·∫°o Features \"Lag/Rolling\"\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- T·∫°o lag features (t-52, t-1, t-2, t-4)\n",
    "- T·∫°o rolling statistics (mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c096189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Lag features created!\n",
      "\n",
      "Lag features missing values:\n",
      "lag_sales_t_52    160487\n",
      "lag_sales_t_1       3331\n",
      "lag_sales_t_2       6625\n",
      "lag_sales_t_4      13134\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o features Lag\n",
    "df_final = df_final.sort_values(['Store', 'Dept', 'WeekEndDate']).reset_index(drop=True)\n",
    "\n",
    "# lag_sales_t_52: Feature \"nƒÉm ngo√°i\" (52 tu·∫ßn tr∆∞·ªõc)\n",
    "df_final['lag_sales_t_52'] = df_final.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(52)\n",
    "\n",
    "# lag_sales_t_1, lag_sales_t_2, lag_sales_t_4: Lag ng·∫Øn h·∫°n\n",
    "df_final['lag_sales_t_1'] = df_final.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1)\n",
    "df_final['lag_sales_t_2'] = df_final.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(2)\n",
    "df_final['lag_sales_t_4'] = df_final.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(4)\n",
    "\n",
    "print(\"‚úÖ Lag features created!\")\n",
    "print(f\"\\nLag features missing values:\")\n",
    "print(df_final[['lag_sales_t_52', 'lag_sales_t_1', 'lag_sales_t_2', 'lag_sales_t_4']].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "049463c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Too many levels: Index has only 1 level, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# T·∫°o features Rolling\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# rolling_mean_sales_4_weeks: Trung b√¨nh 4 tu·∫ßn g·∫ßn nh·∫•t (shift(1) ƒë·ªÉ tr√°nh leakage)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_mean_sales_4_weeks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_final\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDept\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeekly_Sales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# rolling_std_sales_4_weeks: ƒê·ªô l·ªách chu·∫©n 4 tu·∫ßn\u001b[39;00m\n\u001b[1;32m      6\u001b[0m df_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrolling_std_sales_4_weeks\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_final\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDept\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeekly_Sales\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/walmart/lib/python3.10/site-packages/pandas/core/series.py:1754\u001b[0m, in \u001b[0;36mSeries.reset_index\u001b[0;34m(self, level, drop, name, inplace, allow_duplicates)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1753\u001b[0m     level_list \u001b[38;5;241m=\u001b[39m level\n\u001b[0;32m-> 1754\u001b[0m level_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_level_number(lev) \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;129;01min\u001b[39;00m level_list]\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(level_list) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[1;32m   1756\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mdroplevel(level_list)\n",
      "File \u001b[0;32m~/miniconda3/envs/walmart/lib/python3.10/site-packages/pandas/core/series.py:1754\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1753\u001b[0m     level_list \u001b[38;5;241m=\u001b[39m level\n\u001b[0;32m-> 1754\u001b[0m level_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_level_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlev\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;129;01min\u001b[39;00m level_list]\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(level_list) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mnlevels:\n\u001b[1;32m   1756\u001b[0m     new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mdroplevel(level_list)\n",
      "File \u001b[0;32m~/miniconda3/envs/walmart/lib/python3.10/site-packages/pandas/core/indexes/base.py:2024\u001b[0m, in \u001b[0;36mIndex._get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_level_number\u001b[39m(\u001b[38;5;28mself\u001b[39m, level) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m-> 2024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_index_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/walmart/lib/python3.10/site-packages/pandas/core/indexes/base.py:2015\u001b[0m, in \u001b[0;36mIndex._validate_index_level\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   2011\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many levels: Index has only 1 level, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2012\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid level number\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2013\u001b[0m         )\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2015\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[1;32m   2016\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many levels: Index has only 1 level, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2017\u001b[0m         )\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m level \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname:\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   2020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested level (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does not match index name (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: Too many levels: Index has only 1 level, not 2"
     ]
    }
   ],
   "source": [
    "# T·∫°o features Rolling\n",
    "# rolling_mean_sales_4_weeks: Trung b√¨nh 4 tu·∫ßn g·∫ßn nh·∫•t (shift(1) ƒë·ªÉ tr√°nh leakage)\n",
    "df_final['rolling_mean_sales_4_weeks'] = df_final.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1).rolling(window=4, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
    "\n",
    "# rolling_std_sales_4_weeks: ƒê·ªô l·ªách chu·∫©n 4 tu·∫ßn\n",
    "df_final['rolling_std_sales_4_weeks'] = df_final.groupby(['Store', 'Dept'])['Weekly_Sales'].shift(1).rolling(window=4, min_periods=1).std().reset_index(level=[0,1], drop=True)\n",
    "\n",
    "print(\"‚úÖ Rolling features created!\")\n",
    "print(f\"\\nRolling features statistics:\")\n",
    "print(df_final[['rolling_mean_sales_4_weeks', 'rolling_std_sales_4_weeks']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f20a1",
   "metadata": {},
   "source": [
    "## 2.5. T·∫°o Features \"Interaction\"\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- T·∫°o interact_snap_x_type_c\n",
    "- T·∫°o interact_holiday_x_impact\n",
    "- T·∫°o interact_tax_x_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535108eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o features Interaction\n",
    "# interact_snap_x_type_c: SNAP x Store Type C\n",
    "df_final['interact_snap_x_type_c'] = df_final['is_snap_window_1_week'] * (df_final['Type'] == 'C').astype(int)\n",
    "\n",
    "# interact_holiday_x_impact: Pre-Christmas window x holiday impact\n",
    "df_final['interact_holiday_x_impact'] = df_final['is_pre_christmas_window_week'] * df_final['holiday_impact_week']\n",
    "\n",
    "# interact_tax_x_temp: Tax refund season x Temperature\n",
    "df_final['interact_tax_x_temp'] = df_final['is_tax_refund_season_week'] * df_final['Temperature']\n",
    "\n",
    "print(\"‚úÖ Interaction features created!\")\n",
    "print(f\"\\nInteraction features statistics:\")\n",
    "print(df_final[['interact_snap_x_type_c', 'interact_holiday_x_impact', 'interact_tax_x_temp']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829fb9c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# GIAI ƒêO·∫†N 3: L∆ØU C√ÅC FILE OUTPUT\n",
    "\n",
    "**M·ª•c ti√™u:**\n",
    "- L∆∞u df_main_weekly.csv\n",
    "- L∆∞u df_events_daily.csv\n",
    "- L∆∞u df_feature_calendar_weekly.csv\n",
    "- L∆∞u df_final_for_model.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594767a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u c√°c file output\n",
    "print(\"üíæ Saving output files...\")\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c processed n·∫øu ch∆∞a c√≥\n",
    "os.makedirs(PROCESSED_PATH, exist_ok=True)\n",
    "\n",
    "# L∆∞u df_main_weekly\n",
    "df_main_weekly.to_csv(PROCESSED_PATH + 'df_main_weekly.csv', index=False)\n",
    "print(f\"‚úÖ Saved: df_main_weekly.csv ({df_main_weekly.shape})\")\n",
    "\n",
    "# L∆∞u df_events_daily\n",
    "df_events_daily.to_csv(PROCESSED_PATH + 'df_events_daily.csv', index=False)\n",
    "print(f\"‚úÖ Saved: df_events_daily.csv ({df_events_daily.shape})\")\n",
    "\n",
    "# L∆∞u df_feature_calendar_weekly\n",
    "df_feature_calendar_weekly.to_csv(PROCESSED_PATH + 'df_feature_calendar_weekly.csv', index=False)\n",
    "print(f\"‚úÖ Saved: df_feature_calendar_weekly.csv ({df_feature_calendar_weekly.shape})\")\n",
    "\n",
    "# L∆∞u df_final_for_model\n",
    "df_final.to_csv(PROCESSED_PATH + 'df_final_for_model.csv', index=False)\n",
    "print(f\"‚úÖ Saved: df_final_for_model.csv ({df_final.shape})\")\n",
    "\n",
    "print(\"\\nüéâ All files saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38cd45d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# T√ìM T·∫ÆT K·∫æT QU·∫¢\n",
    "\n",
    "## Final Dataset Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üìä FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Final dataset shape: {df_final.shape}\")\n",
    "print(f\"üìä Total columns: {len(df_final.columns)}\")\n",
    "print(f\"üìÖ Time range: {df_final['WeekEndDate'].min()} to {df_final['WeekEndDate'].max()}\")\n",
    "print(f\"üè™ Stores: {df_final['Store'].nunique()}, Departments: {df_final['Dept'].nunique()}\")\n",
    "\n",
    "print(f\"\\nüí∞ Weekly Sales statistics:\")\n",
    "print(df_final['Weekly_Sales'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fa552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìã All columns ({len(df_final.columns)}):\")\n",
    "for i, col in enumerate(df_final.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DATA PREPARATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84613052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem sample c·ªßa df_final\n",
    "print(\"Sample of final dataset:\")\n",
    "df_final.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Walmart)",
   "language": "python",
   "name": "walmart"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
